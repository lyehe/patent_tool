{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "res = requests.get('https://patents.google.com/patent/US12178887B2/en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.html', 'w', encoding='utf-8') as f:\n",
    "    f.write(res.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patent Number: US20230241253A1\n",
      "Title: NIR-conjugated tumor-specific antibodies and uses thereof\n",
      "Assignees: \n",
      "Inventors: \n",
      "Priority Date: \n",
      "Filing Date: \n",
      "Publication Date: \n",
      "Grant Date: \n",
      "Abstract: Disclosed is a tumor-specific antibody and fluorophore conjugate for detecting, localizing and imagi...\n",
      "Description: PRIORITY CLAIM\n",
      "This application is a continuation of U.S. application Ser. No. 16/993,950, entitled ...\n",
      "Claims: 7 claims found\n",
      "\n",
      "Patent data saved to patent_data.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "@dataclass\n",
    "class PatentClaim:\n",
    "    \"\"\"Class for storing patent claim information\"\"\"\n",
    "    number: int\n",
    "    text: str\n",
    "    dependent_on: Optional[int] = None\n",
    "\n",
    "@dataclass\n",
    "class PatentData:\n",
    "    \"\"\"Class for storing comprehensive patent information\"\"\"\n",
    "    patent_number: str = \"\"\n",
    "    title: str = \"\"\n",
    "    assignees: List[str] = field(default_factory=list)\n",
    "    inventors: List[str] = field(default_factory=list)\n",
    "    priority_date: str = \"\"\n",
    "    filing_date: str = \"\"\n",
    "    publication_date: str = \"\"\n",
    "    grant_date: str = \"\"\n",
    "    abstract: str = \"\"\n",
    "    description: str = \"\"\n",
    "    claims: List[PatentClaim] = field(default_factory=list)\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        \"\"\"String representation for printing\"\"\"\n",
    "        return (\n",
    "            f\"Patent Number: {self.patent_number}\\n\"\n",
    "            f\"Title: {self.title}\\n\"\n",
    "            f\"Assignees: {', '.join(self.assignees)}\\n\"\n",
    "            f\"Inventors: {', '.join(self.inventors)}\\n\"\n",
    "            f\"Priority Date: {self.priority_date}\\n\"\n",
    "            f\"Filing Date: {self.filing_date}\\n\"\n",
    "            f\"Publication Date: {self.publication_date}\\n\"\n",
    "            f\"Grant Date: {self.grant_date}\\n\"\n",
    "            f\"Abstract: {self.abstract[:100]}...\\n\"\n",
    "            f\"Description: {self.description[:100]}...\\n\"\n",
    "            f\"Claims: {len(self.claims)} claims found\"\n",
    "        )\n",
    "\n",
    "def extract_patent_data(html_file: str) -> PatentData:\n",
    "    \"\"\"\n",
    "    Extract patent information from HTML file using BeautifulSoup\n",
    "    \n",
    "    :param html_file: Path to the HTML file\n",
    "    :return: PatentData object with extracted information\n",
    "    \"\"\"\n",
    "    # Read the HTML file\n",
    "    with open(html_file, 'r', encoding='utf-8') as f:\n",
    "        html_content = f.read()\n",
    "    \n",
    "    # Parse with BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Initialize patent data\n",
    "    patent_data = PatentData()\n",
    "    \n",
    "    # Extract patent number/ID\n",
    "    patent_number_elem = soup.find('span', {'itemprop': 'publicationNumber'})\n",
    "    if patent_number_elem:\n",
    "        patent_data.patent_number = patent_number_elem.text.strip()\n",
    "    else:\n",
    "        # Try alternative selectors\n",
    "        patent_number_elem = soup.find('meta', {'name': 'citation_patent_number'})\n",
    "        if patent_number_elem:\n",
    "            patent_data.patent_number = patent_number_elem.get('content', '')\n",
    "    \n",
    "    # Extract title\n",
    "    title_elem = soup.find('span', {'itemprop': 'title'})\n",
    "    if title_elem:\n",
    "        patent_data.title = title_elem.text.strip()\n",
    "    else:\n",
    "        # Try alternative selectors\n",
    "        title_elem = soup.find('meta', {'name': 'citation_title'})\n",
    "        if title_elem:\n",
    "            patent_data.title = title_elem.get('content', '')\n",
    "    \n",
    "    # Extract assignees\n",
    "    assignee_elems = soup.find_all('span', {'itemprop': 'assignee'})\n",
    "    for elem in assignee_elems:\n",
    "        assignee_name = elem.text.strip()\n",
    "        if assignee_name:\n",
    "            patent_data.assignees.append(assignee_name)\n",
    "    \n",
    "    # Extract inventors\n",
    "    inventor_elems = soup.find_all('span', {'itemprop': 'inventor'})\n",
    "    for elem in inventor_elems:\n",
    "        inventor_name = elem.text.strip()\n",
    "        if inventor_name:\n",
    "            patent_data.inventors.append(inventor_name)\n",
    "    \n",
    "    # Extract dates\n",
    "    # Look for specific date elements\n",
    "    for date_type in ['priority', 'filing', 'publication', 'grant']:\n",
    "        date_elem = soup.find('dd', {'itemprop': f'{date_type}Date'})\n",
    "        if date_elem:\n",
    "            setattr(patent_data, f\"{date_type}_date\", date_elem.text.strip())\n",
    "    \n",
    "    # Extract abstract\n",
    "    abstract_elem = soup.find('div', {'class': 'abstract'})\n",
    "    if abstract_elem:\n",
    "        patent_data.abstract = abstract_elem.text.strip()\n",
    "    else:\n",
    "        # Try alternative selectors\n",
    "        abstract_elem = soup.find('section', {'itemprop': 'abstract'})\n",
    "        if abstract_elem:\n",
    "            patent_data.abstract = abstract_elem.text.strip()\n",
    "    \n",
    "    # Extract description\n",
    "    description_elem = soup.find('div', {'class': 'description'})\n",
    "    if description_elem:\n",
    "        patent_data.description = description_elem.text.strip()\n",
    "    else:\n",
    "        # Try alternative selectors\n",
    "        description_elem = soup.find('section', {'itemprop': 'description'})\n",
    "        if description_elem:\n",
    "            patent_data.description = description_elem.text.strip()\n",
    "    \n",
    "    # Extract claims\n",
    "    claims_section = soup.find('section', {'itemprop': 'claims'})\n",
    "    if claims_section:\n",
    "        claim_elements = claims_section.find_all(['div', 'p'], {'class': 'claim'})\n",
    "        if not claim_elements:\n",
    "            claim_elements = claims_section.find_all('li')\n",
    "        \n",
    "        for i, elem in enumerate(claim_elements, 1):\n",
    "            claim_text = elem.text.strip()\n",
    "            \n",
    "            # Try to extract claim number\n",
    "            num_span = elem.find('span', {'class': 'claim-number'})\n",
    "            claim_num = int(num_span.text.strip().replace('.', '')) if num_span else i\n",
    "            \n",
    "            # Check for dependency\n",
    "            dependent_on = None\n",
    "            if claim_num > 1 and \"claim\" in claim_text.lower():\n",
    "                import re\n",
    "                dep_match = re.search(r'(?:according to|as claimed in|of)\\s+claim\\s+(\\d+)', claim_text.lower())\n",
    "                if dep_match:\n",
    "                    dependent_on = int(dep_match.group(1))\n",
    "            \n",
    "            patent_data.claims.append(PatentClaim(\n",
    "                number=claim_num,\n",
    "                text=claim_text,\n",
    "                dependent_on=dependent_on\n",
    "            ))\n",
    "    \n",
    "    return patent_data\n",
    "\n",
    "def save_to_file(patent_data: PatentData, output_file: str) -> None:\n",
    "    \"\"\"\n",
    "    Save extracted patent data to a text file\n",
    "    \n",
    "    :param patent_data: PatentData object with patent information\n",
    "    :param output_file: Path to the output file\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"Patent Number: {patent_data.patent_number}\\n\")\n",
    "        f.write(f\"Title: {patent_data.title}\\n\")\n",
    "        \n",
    "        f.write(\"\\n===== DATES =====\\n\")\n",
    "        f.write(f\"Priority Date: {patent_data.priority_date}\\n\")\n",
    "        f.write(f\"Filing Date: {patent_data.filing_date}\\n\")\n",
    "        f.write(f\"Publication Date: {patent_data.publication_date}\\n\")\n",
    "        f.write(f\"Grant Date: {patent_data.grant_date}\\n\")\n",
    "        \n",
    "        f.write(\"\\n===== ASSIGNEES =====\\n\")\n",
    "        for assignee in patent_data.assignees:\n",
    "            f.write(f\"{assignee}\\n\")\n",
    "        \n",
    "        f.write(\"\\n===== INVENTORS =====\\n\")\n",
    "        for inventor in patent_data.inventors:\n",
    "            f.write(f\"{inventor}\\n\")\n",
    "        \n",
    "        f.write(\"\\n===== ABSTRACT =====\\n\")\n",
    "        f.write(f\"{patent_data.abstract}\\n\")\n",
    "        \n",
    "        f.write(\"\\n===== DESCRIPTION =====\\n\")\n",
    "        f.write(f\"{patent_data.description}\\n\")\n",
    "        \n",
    "        f.write(\"\\n===== CLAIMS =====\\n\")\n",
    "        for claim in patent_data.claims:\n",
    "            f.write(f\"Claim {claim.number}: {claim.text}\\n\")\n",
    "            if claim.dependent_on:\n",
    "                f.write(f\"  Dependent on claim {claim.dependent_on}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to extract patent data from HTML file\"\"\"\n",
    "    # Input and output file paths\n",
    "    html_file = \"test.html\"\n",
    "    output_file = \"patent_data.txt\"\n",
    "    \n",
    "    # Extract patent data\n",
    "    patent_data = extract_patent_data(html_file)\n",
    "    \n",
    "    # Print summary\n",
    "    print(patent_data)\n",
    "    \n",
    "    # Save to file\n",
    "    save_to_file(patent_data, output_file)\n",
    "    print(f\"\\nPatent data saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
